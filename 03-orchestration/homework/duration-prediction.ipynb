{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2bd82d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.1\n"
     ]
    }
   ],
   "source": [
    "# Check Python version to ensure compatibility with required libraries\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41062d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for data manipulation and analysis\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c984c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pickle for saving and loading Python objects\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b135c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DictVectorizer (converts feature dicts to vectors, one-hot encoding categoricals) and RMSE metric for evaluation\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1464985f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1751795868559, experiment_id='1', last_update_time=1751795868559, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import MLflow and set up experiment tracking\n",
    "import mlflow\n",
    "\n",
    "# Set the MLflow tracking URI to local server\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "# Set the experiment name for MLflow runs\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9e6479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read and preprocess the NYC taxi data\n",
    "def read_dataframe(filename):\n",
    "    # Read parquet file into DataFrame\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    # Calculate trip duration in minutes\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    # Filter out trips with duration less than 1 minute or more than 60 minutes\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    # Convert categorical columns to string type\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    # Create a combined pickup-dropoff feature\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8029eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess training and validation datasets\n",
    "df_train = read_dataframe('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-01.parquet')\n",
    "df_val = read_dataframe('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5cbfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for the model\n",
    "categorical = ['PU_DO']  # Combined pickup and dropoff location as categorical feature\n",
    "numerical = ['trip_distance']  # Trip distance as numerical feature\n",
    "\n",
    "# Initialize DictVectorizer to convert feature dictionaries to feature vectors\n",
    "dv = DictVectorizer()\n",
    "\n",
    "# Prepare training data as a list of dictionaries for the vectorizer\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)  # Fit vectorizer and transform training data\n",
    "\n",
    "# Prepare validation data as a list of dictionaries for the vectorizer\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)  # Transform validation data using fitted vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e9fb68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract target variable (duration) for training and validation sets\n",
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f56e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import xgboost for training the regression model\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1f71259-0e96-4725-9151-dc274f4e984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Path for handling filesystem paths\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ee76202-3ff6-4bd7-b70e-b8d1c87c26d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to store trained models if it doesn't exist\n",
    "models_folder = Path('models')\n",
    "models_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e8cd729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/xgboost/callback.py:386: UserWarning: [09:58:50] WARNING: /workspace/src/objective/regression_obj.cu:250: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:11.44482\n",
      "[1]\tvalidation-rmse:10.77202\n",
      "[1]\tvalidation-rmse:10.77202\n",
      "[2]\tvalidation-rmse:10.18363\n",
      "[2]\tvalidation-rmse:10.18363\n",
      "[3]\tvalidation-rmse:9.67396\n",
      "[3]\tvalidation-rmse:9.67396\n",
      "[4]\tvalidation-rmse:9.23166\n",
      "[4]\tvalidation-rmse:9.23166\n",
      "[5]\tvalidation-rmse:8.84808\n",
      "[5]\tvalidation-rmse:8.84808\n",
      "[6]\tvalidation-rmse:8.51883\n",
      "[6]\tvalidation-rmse:8.51883\n",
      "[7]\tvalidation-rmse:8.23597\n",
      "[7]\tvalidation-rmse:8.23597\n",
      "[8]\tvalidation-rmse:7.99320\n",
      "[8]\tvalidation-rmse:7.99320\n",
      "[9]\tvalidation-rmse:7.78709\n",
      "[9]\tvalidation-rmse:7.78709\n",
      "[10]\tvalidation-rmse:7.61022\n",
      "[10]\tvalidation-rmse:7.61022\n",
      "[11]\tvalidation-rmse:7.45952\n",
      "[11]\tvalidation-rmse:7.45952\n",
      "[12]\tvalidation-rmse:7.33049\n",
      "[12]\tvalidation-rmse:7.33049\n",
      "[13]\tvalidation-rmse:7.22098\n",
      "[13]\tvalidation-rmse:7.22098\n",
      "[14]\tvalidation-rmse:7.12713\n",
      "[14]\tvalidation-rmse:7.12713\n",
      "[15]\tvalidation-rmse:7.04752\n",
      "[15]\tvalidation-rmse:7.04752\n",
      "[16]\tvalidation-rmse:6.98005\n",
      "[16]\tvalidation-rmse:6.98005\n",
      "[17]\tvalidation-rmse:6.92232\n",
      "[17]\tvalidation-rmse:6.92232\n",
      "[18]\tvalidation-rmse:6.87112\n",
      "[18]\tvalidation-rmse:6.87112\n",
      "[19]\tvalidation-rmse:6.82740\n",
      "[19]\tvalidation-rmse:6.82740\n",
      "[20]\tvalidation-rmse:6.78995\n",
      "[20]\tvalidation-rmse:6.78995\n",
      "[21]\tvalidation-rmse:6.75792\n",
      "[21]\tvalidation-rmse:6.75792\n",
      "[22]\tvalidation-rmse:6.72994\n",
      "[22]\tvalidation-rmse:6.72994\n",
      "[23]\tvalidation-rmse:6.70547\n",
      "[23]\tvalidation-rmse:6.70547\n",
      "[24]\tvalidation-rmse:6.68390\n",
      "[24]\tvalidation-rmse:6.68390\n",
      "[25]\tvalidation-rmse:6.66421\n",
      "[25]\tvalidation-rmse:6.66421\n",
      "[26]\tvalidation-rmse:6.64806\n",
      "[26]\tvalidation-rmse:6.64806\n",
      "[27]\tvalidation-rmse:6.63280\n",
      "[27]\tvalidation-rmse:6.63280\n",
      "[28]\tvalidation-rmse:6.61924\n",
      "[28]\tvalidation-rmse:6.61924\n",
      "[29]\tvalidation-rmse:6.60773\n",
      "[29]\tvalidation-rmse:6.60773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/mlflow/xgboost/__init__.py:168: UserWarning: [09:59:08] WARNING: /workspace/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  xgb_model.save_model(model_data_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run gifted-crane-33 at: http://localhost:5000/#/experiments/1/runs/bbc576251d204e4ca476c403e7222e39\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# Start an MLflow run to track experiment\n",
    "with mlflow.start_run():\n",
    "    # Prepare DMatrix for XGBoost\n",
    "    train = xgb.DMatrix(X_train, label=y_train)\n",
    "    valid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    # Best hyperparameters found from tuning\n",
    "    best_params = {\n",
    "        'learning_rate': 0.09585355369315604,\n",
    "        'max_depth': 30,\n",
    "        'min_child_weight': 1.060597050922164,\n",
    "        'objective': 'reg:linear',\n",
    "        'reg_alpha': 0.018060244040060163,\n",
    "        'reg_lambda': 0.011658731377413597,\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    # Log hyperparameters to MLflow\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Train XGBoost model with early stopping\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=30,\n",
    "        evals=[(valid, 'validation')],\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "\n",
    "    # Predict on validation set and calculate RMSE\n",
    "    y_pred = booster.predict(valid)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Save the preprocessor (DictVectorizer)\n",
    "    with open(\"models/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "    mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "    # Add signature and input_example to suppress MLflow warning\n",
    "    import numpy as np\n",
    "    from mlflow.models.signature import infer_signature\n",
    "    input_example = X_val[0:2] if hasattr(X_val, 'shape') else np.array(list(val_dicts)[:2])\n",
    "    signature = infer_signature(X_val, y_val)\n",
    "\n",
    "    # Log the trained XGBoost model to MLflow\n",
    "    mlflow.xgboost.log_model(\n",
    "        booster,\n",
    "        name=\"models_mlflow\",\n",
    "        signature=signature,\n",
    "        input_example=input_example\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2108f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
