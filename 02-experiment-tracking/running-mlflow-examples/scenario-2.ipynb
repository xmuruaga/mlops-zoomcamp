{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2: A cross-functional team with one data scientist working on an ML model\n",
    "\n",
    "This scenario demonstrates how a data scientist can use MLflow to track machine learning experiments in a team setting, using a centralized tracking server. This setup is common in organizations where multiple people need to access experiment results, models, and artifacts.\n",
    "\n",
    "### MLflow setup overview:\n",
    "- **Tracking server:** Yes (runs as a local server, accessible to the team)\n",
    "- **Backend store:** SQLite database (stores experiment metadata in `backend.db`)\n",
    "- **Artifacts store:** Local filesystem (stores model files and other artifacts)\n",
    "\n",
    "With this setup, all experiment runs, parameters, metrics, and artifacts are saved in a central location. Team members can explore and compare experiments using the MLflow UI, even from different machines (if the server is accessible).\n",
    "\n",
    "### How to use the MLflow tracking server and UI\n",
    "- **First, you must launch the MLflow tracking server** by running the following command in your terminal:\n",
    "  ```bash\n",
    "  mlflow server --backend-store-uri sqlite:///backend.db\n",
    "  ```\n",
    "- The UI will be available at the address printed in your terminal (by default, [http://localhost:5000](http://localhost:5000)).\n",
    "- If you run the server on a remote machine or a different port, use the appropriate address (e.g., `http://<your-server>:<port>`).\n",
    "- Use the UI to browse experiments, compare runs, and inspect logged models and artifacts.\n",
    "- You can also interact with the model registry for collaborative model management.\n",
    "\n",
    "> **Tip:** This setup is ideal for small teams and collaborative projects. For larger teams or production, you may use a remote database and cloud storage for the backend and artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://127.0.0.1:5000'\n"
     ]
    }
   ],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1751191587046, experiment_id='0', last_update_time=1751191587046, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/29 10:06:36 INFO mlflow.tracking.fluent: Experiment with name 'my-experiment-1' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run for C=0.01, accuracy=0.873\n",
      "üèÉ View run melodic-zebra-89 at: http://127.0.0.1:5000/#/experiments/1/runs/60350aa0096443459d01e870998b062d\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1\n",
      "Logged run for C=0.1, accuracy=0.960\n",
      "üèÉ View run likeable-zebra-336 at: http://127.0.0.1:5000/#/experiments/1/runs/7c60cc80407b449ea25e8c373300d049\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1\n",
      "Logged run for C=1, accuracy=0.973\n",
      "üèÉ View run masked-dog-634 at: http://127.0.0.1:5000/#/experiments/1/runs/8723a6a2a1784627ae29552ba64befff\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1\n",
      "Logged run for C=10, accuracy=0.980\n",
      "üèÉ View run respected-duck-790 at: http://127.0.0.1:5000/#/experiments/1/runs/bf94a0c925c44f69ac6fd1cb26d3046f\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import sklearn\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "mlflow.set_experiment(\"my-experiment-1\")\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "class_names = load_iris().target_names\n",
    "\n",
    "# Try several values of C to demonstrate experiment tracking\n",
    "for C in [0.01, 0.1, 1, 10]:\n",
    "    params = {\"C\": C, \"random_state\": 42, \"max_iter\": 1000, \"solver\": \"lbfgs\"}\n",
    "    with mlflow.start_run() as run:\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_param(\"sklearn_version\", sklearn.__version__)\n",
    "        lr = LogisticRegression(**params).fit(X, y)\n",
    "        y_pred = lr.predict(X)\n",
    "        acc = accuracy_score(y, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        # Log model coefficients as params (flattened for logging)\n",
    "        for i, coef in enumerate(lr.coef_.flatten()):\n",
    "            mlflow.log_param(f\"coef_{i}\", coef)\n",
    "        # Labeled confusion matrix as DataFrame\n",
    "        cm = confusion_matrix(y, y_pred)\n",
    "        cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "        cm_df.to_csv(\"confusion_matrix_labeled.csv\")\n",
    "        mlflow.log_artifact(\"confusion_matrix_labeled.csv\")\n",
    "        # Confusion matrix heatmap as image\n",
    "        plt.figure(figsize=(5,4))\n",
    "        sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title(f\"Confusion Matrix (C={C})\")\n",
    "        plt.ylabel(\"True label\")\n",
    "        plt.xlabel(\"Predicted label\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"confusion_matrix_heatmap.png\")\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(\"confusion_matrix_heatmap.png\")\n",
    "        # Provide input_example and use 'name' instead of deprecated 'artifact_path'\n",
    "        input_example = np.expand_dims(X[0], axis=0)\n",
    "        mlflow.sklearn.log_model(lr, name=\"models\", input_example=input_example)\n",
    "        # Log model type, number of classes, and timestamp as tags\n",
    "        mlflow.set_tag(\"model_type\", type(lr).__name__)\n",
    "        mlflow.set_tag(\"n_classes\", len(np.unique(y)))\n",
    "        mlflow.set_tag(\"run_time\", datetime.datetime.now().isoformat())\n",
    "        mlflow.set_tag(\"description\", \"Logistic regression on Iris dataset with varying C\")\n",
    "        print(f\"Logged run for C={C}, accuracy={acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1751191596295, experiment_id='1', last_update_time=1751191596295, lifecycle_stage='active', name='my-experiment-1', tags={}>,\n",
       " <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1751191587046, experiment_id='0', last_update_time=1751191587046, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with the model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "client = MlflowClient(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.search_registered_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'iris-classifier'.\n",
      "2025/06/29 10:06:48 WARNING mlflow.tracking._model_registry.fluent: Run with id bf94a0c925c44f69ac6fd1cb26d3046f has no artifacts at artifact path 'models', registering model based on models:/m-e4c3fea03d0a48dc9a99e585f54eeff5 instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/29 10:06:48 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: iris-classifier, version 1\n",
      "Created version '1' of model 'iris-classifier'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1751191608717, current_stage='None', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1751191608717, metrics=None, model_id=None, name='iris-classifier', params=None, run_id='bf94a0c925c44f69ac6fd1cb26d3046f', run_link='', source='models:/m-e4c3fea03d0a48dc9a99e585f54eeff5', status='READY', status_message=None, tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = client.search_runs(experiment_ids='1')[0].info.run_id\n",
    "mlflow.register_model(\n",
    "    model_uri=f\"runs:/{run_id}/models\",\n",
    "    name='iris-classifier'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
